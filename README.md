# ğŸ“š Insurance Knowledge Base - RAG System

Sistema RAG (Retrieval-Augmented Generation) completo para consulta de produtos de seguro com chatbot web, incluindo:

- ğŸš€ **Frontend**: Next.js 14 + TypeScript + Tailwind CSS
- âš¡ **Backend**: FastAPI + Python 3.11+
- ğŸ” **Vector DB**: Qdrant para pesquisa semÃ¢ntica
- ğŸ§  **RAG Pipeline**: Embeddings locais (BGE), re-ranking, citaÃ§Ãµes
- ğŸ›¡ï¸ **Guardrails**: DetecÃ§Ã£o de prompt injection, rate limiting
- ğŸ“Š **AvaliaÃ§Ã£o**: RAGAS para mÃ©tricas de qualidade
- ğŸ³ **Docker**: Stack completa com Docker Compose

---

## ğŸ¯ Guia de FormaÃ§Ã£o

> **ğŸ“š NOVO! Guia Master Completo:** [**GUIA-FORMACAO.md**](GUIA-FORMACAO.md) 
>
> âœ¨ Tudo que vocÃª precisa desde instalaÃ§Ã£o atÃ© uso avanÃ§ado num Ãºnico documento!

### Guias DisponÃ­veis

| Guia | Para Quem | ConteÃºdo |
|------|-----------|----------|
| ğŸ“š [**GUIA-FORMACAO.md**](GUIA-FORMACAO.md) | **TODOS** â­ | Guia completo: instalaÃ§Ã£o, uso, validaÃ§Ã£o, embeddings, desenvolvimento |
| ğŸ‘¨â€ğŸ« [**CHECKLIST-PROFESSOR.md**](CHECKLIST-PROFESSOR.md) | Professores | PreparaÃ§Ã£o de aulas e gestÃ£o de turma |
| ğŸ“ [**MUDANCAS.md**](MUDANCAS.md) | Curiosos | HistÃ³rico de melhorias do projeto |

---

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitetura](#-arquitetura)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [UtilizaÃ§Ã£o](#-utilizaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Desenvolvimento](#-desenvolvimento)
- [Testes](#-testes)
- [AvaliaÃ§Ã£o](#-avaliaÃ§Ã£o)
- [Troubleshooting](#-troubleshooting)
- [Estrutura do Projeto](#-estrutura-do-projeto)

## âœ¨ CaracterÃ­sticas

### Frontend
- Interface de chat moderna e responsiva
- Streaming de respostas em tempo real
- Painel lateral com fontes citadas
- Indicadores de latÃªncia e uso de tokens
- Dark mode support

### Backend RAG
- **Embeddings**: BGE-large-en-v1.5 local (opcional OpenAI)
- **Retrieval**: Qdrant com pesquisa por cosine similarity
- **Re-ranking**: BGE-reranker-base para melhor relevÃ¢ncia
- **LLM**: OpenAI (gpt-4o-mini) ou Azure OpenAI
- **Chunking**: HierÃ¡rquico preservando estrutura de documentos
- **CitaÃ§Ãµes**: ReferÃªncias automÃ¡ticas com tÃ­tulo, pÃ¡gina e excerto

### SeguranÃ§a & Guardrails
- Rate limiting por IP
- DetecÃ§Ã£o de prompt injection
- SanitizaÃ§Ã£o de queries
- Termos bloqueados configurÃ¡veis
- Limite de contexto e tokens

### Observabilidade
- Logging estruturado (JSON)
- MÃ©tricas de latÃªncia por componente
- Contagem de tokens
- Tracking de documentos recuperados

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â”‚  (Next.js)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP/REST
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚
â”‚     API     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚          â”‚
       â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qdrant  â”‚  â”‚   LLM    â”‚
â”‚ VectorDB â”‚  â”‚ (OpenAI) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline RAG

```
Query â†’ Sanitize â†’ Embed â†’ Retrieve (Qdrant) â†’ Re-rank â†’ 
Build Prompt â†’ LLM Generate â†’ Extract Citations â†’ Response
```

## ğŸ“¦ PrÃ©-requisitos

- **Docker** & **Docker Compose** (recomendado)
- OU
  - Python 3.11+
  - Node.js 20+
  - Qdrant (local ou cloud)

### APIs (Opcional)
- **OpenAI API Key**: Para LLM e embeddings OpenAI
- **Azure OpenAI**: Alternativa ao OpenAI
- **Cohere API Key**: Para re-ranking Cohere (opcional)

> **Nota**: O sistema funciona **sem chaves de API** usando modelos locais (embeddings BGE) e um provider dummy para testes. Para produÃ§Ã£o, configure pelo menos a OpenAI API key.

## ğŸš€ InstalaÃ§Ã£o

> **ğŸ“š RECOMENDADO:** Siga o [**GUIA-FORMACAO.md**](GUIA-FORMACAO.md) - Guia completo passo a passo!

### InstalaÃ§Ã£o Local (Windows) - Recomendado para FormaÃ§Ã£o

**Veja passo a passo completo em:** [**GUIA-FORMACAO.md â†’ SeÃ§Ã£o 2**](GUIA-FORMACAO.md#-2-instalaÃ§Ã£o-completa)

**Resumo rÃ¡pido:**

```powershell
# 1. Configurar .env
copy env.example .env
notepad .env  # Adicionar suas chaves

# 2. Instalar Backend
cd api
python -m venv venv
.\install-all.bat

# 3. Instalar Frontend
cd ..\web
npm install
```

### InstalaÃ§Ã£o com Docker (AvanÃ§ado)

```bash
# Build completo com embeddings locais
make dev

# OU build rÃ¡pido (requer OpenAI key)
make dev-fast
```

---

Aguarde atÃ© todos os serviÃ§os estarem rodando:
- âœ… Qdrant: http://localhost:6333
- âœ… API: http://localhost:8000
- âœ… Web: http://localhost:3000

## ğŸ’¡ UtilizaÃ§Ã£o

### 1. Verificar saÃºde do sistema

```bash
make health
```

Ou:

```bash
curl http://localhost:8000/health
```

### 2. Ingerir documentos

Coloque seus PDFs, DOCX ou TXT em `data/pdfs/` (jÃ¡ incluÃ­dos 3 exemplos em TXT) e execute:

```bash
make ingest
```

Ou:

```bash
curl -X POST http://localhost:8000/ingest
```

Resposta esperada:
```json
{
  "files_processed": 3,
  "chunks_created": 150,
  "documents_upserted": 150,
  "elapsed_seconds": 12.5,
  "status": "success"
}
```

### 3. Usar o chatbot

Abra http://localhost:3000 no navegador e faÃ§a perguntas como:

- "Quais as exclusÃµes da cobertura de Danos PrÃ³prios no seguro Auto?"
- "Qual Ã© o perÃ­odo de carÃªncia para cirurgias?"
- "O seguro de SaÃºde cobre implantes dentÃ¡rios?"

### 4. Testar via API

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Quais as coberturas do seguro Auto?",
    "top_k": 5
  }'
```

### 5. Com filtros por produto

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Qual a franquia?",
    "top_k": 5,
    "filters": {
      "product": "Auto"
    }
  }'
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente Principais

| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `OPENAI_API_KEY` | Chave API OpenAI | - |
| `LLM_MODEL` | Modelo LLM | `gpt-4o-mini` |
| `EMBEDDINGS_PROVIDER` | `local` ou `openai` | `local` |
| `LOCAL_EMBEDDING_MODEL` | Modelo BGE | `BAAI/bge-large-en-v1.5` |
| `TOP_K` | Docs a recuperar | `6` |
| `RERANK_TOP_K` | Docs apÃ³s re-ranking | `3` |
| `CHUNK_SIZE` | Tamanho dos chunks | `800` |
| `MAX_CONTEXT_CHARS` | Limite de contexto | `12000` |
| `BLOCKED_TERMS` | Termos bloqueados | `segredo;senha;...` |
| `RATE_LIMIT_PER_MINUTE` | Limite de requisiÃ§Ãµes | `20` |

### ConfiguraÃ§Ã£o de Embeddings

#### Embeddings Locais (PadrÃ£o - Sem API Key)
```bash
EMBEDDINGS_PROVIDER=local
LOCAL_EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
```

**Vantagens**: Gratuito, privado, funciona offline  
**Desvantagens**: Requer GPU para melhor performance (funciona em CPU)

#### Embeddings OpenAI
```bash
EMBEDDINGS_PROVIDER=openai
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
OPENAI_API_KEY=sk-...
```

**Vantagens**: RÃ¡pido, sem recursos locais  
**Desvantagens**: Custo por requisiÃ§Ã£o, requer internet

### ConfiguraÃ§Ã£o de LLM

#### OpenAI
```bash
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
OPENAI_API_KEY=sk-...
```

#### Azure OpenAI
```bash
LLM_PROVIDER=azure
AZURE_OPENAI_ENDPOINT=https://seu-recurso.openai.azure.com/
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini
```

### Re-ranking

#### Local (BGE - PadrÃ£o)
```bash
RERANKER=local
LOCAL_RERANKER_MODEL=BAAI/bge-reranker-base
```

#### Cohere (Opcional)
```bash
RERANKER=cohere
COHERE_API_KEY=...
```

## ğŸ› ï¸ Desenvolvimento

### Estrutura de desenvolvimento

```bash
# Backend (FastAPI)
cd api
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload

# Frontend (Next.js)
cd web
npm install
npm run dev
```

### Adicionar novos documentos

1. Coloque PDFs, DOCX ou TXT em `data/pdfs/`
2. Execute `make ingest`
3. Os documentos serÃ£o:
   - ExtraÃ­dos (texto + metadados)
   - Divididos em chunks
   - Convertidos em embeddings
   - Armazenados no Qdrant

**Formatos suportados:**
- `.pdf` - PDFs com texto extraÃ­vel
- `.docx` - Documentos Word
- `.txt` - Ficheiros de texto simples (UTF-8)

### Formato de Metadados

Cada chunk armazenado contÃ©m:
```json
{
  "text": "ConteÃºdo do chunk...",
  "doc_id": "nome_documento_pagina",
  "title": "Nome do Documento",
  "section": "SecÃ§Ã£o/Heading",
  "page": 5,
  "source_path": "caminho/ficheiro.pdf",
  "chunk_index": 42
}
```

### Personalizar o System Prompt

Edite `api/app/rag/pipeline.py`, mÃ©todo `_get_system_prompt()`:

```python
def _get_system_prompt(self) -> str:
    return """Ã‰s um assistente especializado em produtos de seguro.
    
Regras:
1. Responde APENAS com base nas fontes
2. Inclui SEMPRE citaÃ§Ãµes
3. ...
"""
```

## ğŸ§ª Testes

### Testes da API

```bash
make test-api
```

Ou:

```bash
cd api
pytest -v
```

Cobertura dos testes:
- âœ… Endpoint `/health`
- âœ… Endpoint `/chat` (com mock)
- âœ… Endpoint `/ingest` (com mock)
- âœ… Rate limiting
- âœ… ValidaÃ§Ã£o de inputs
- âœ… Tratamento de erros

### Testes do Frontend

```bash
make test-web
```

## ğŸ“Š AvaliaÃ§Ã£o

### AvaliaÃ§Ã£o BÃ¡sica (Sempre DisponÃ­vel)

O sistema inclui avaliaÃ§Ã£o bÃ¡sica que **nÃ£o requer dependÃªncias extras**:

```bash
make eval
```

Ou:

```bash
docker compose -f infra/docker-compose.yml exec api python eval/run_ragas.py
```

Isto executa todas as perguntas do ground truth e mostra:
- Perguntas vs Respostas geradas
- Contextos recuperados
- Salva resultados em `data/evaluation_results_basic.json`

### AvaliaÃ§Ã£o AvanÃ§ada com RAGAS (Opcional)

Para mÃ©tricas avanÃ§adas (faithfulness, relevancy, etc.), instale as dependÃªncias de avaliaÃ§Ã£o:

```bash
# Dentro do container API
docker compose -f infra/docker-compose.yml exec api pip install -r requirements-eval.txt

# Depois execute a avaliaÃ§Ã£o
make eval
```

> **Nota**: RAGAS requer OpenAI API key e adiciona ~500MB de dependÃªncias (langchain, etc.)

### MÃ©tricas Avaliadas

- **Faithfulness**: QuÃ£o fiel Ã© a resposta ao contexto recuperado?
- **Answer Relevancy**: QuÃ£o relevante Ã© a resposta para a pergunta?
- **Context Recall**: O contexto recuperado cobre a resposta esperada?
- **Context Precision**: Os documentos relevantes estÃ£o bem ranqueados?

### Ground Truth

Adicione pares pergunta-resposta em `data/groundtruth/qa.jsonl`:

```json
{
  "question": "Pergunta exemplo?",
  "answer": "Resposta esperada...",
  "metadata": {"product": "Auto"}
}
```

O sistema jÃ¡ inclui 15 exemplos para comeÃ§ar.

### Resultados

Os resultados sÃ£o salvos em `data/evaluation_results.json`:

```json
{
  "faithfulness": 0.87,
  "answer_relevancy": 0.91,
  "context_recall": 0.84,
  "context_precision": 0.78
}
```

## ğŸ”§ Troubleshooting

### Problema: Erro ao instalar dependÃªncias no Docker

**Sintoma**: `Failed to establish a new connection` durante build

**Causas**:
- Problema de conexÃ£o internet/DNS
- Proxy/firewall bloqueando
- DependÃªncias muito pesadas (RAGAS/langchain)

**SoluÃ§Ã£o**:
```bash
# Limpar cache e tentar novamente
docker compose -f infra/docker-compose.yml down
docker system prune -f
docker compose -f infra/docker-compose.yml up --build
```

O sistema agora usa **apenas dependÃªncias core** (rÃ¡pidas e leves). RAGAS Ã© opcional.

### Problema: Modelos locais muito lentos

**SoluÃ§Ã£o 1**: Use GPU se disponÃ­vel
```bash
# No Dockerfile da API, adicione suporte CUDA
# Ou use CPU com batch pequeno (jÃ¡ configurado)
```

**SoluÃ§Ã£o 2**: Use embeddings OpenAI
```bash
EMBEDDINGS_PROVIDER=openai
```

### Problema: Qdrant nÃ£o inicia

**Verificar**:
```bash
docker compose -f infra/docker-compose.yml logs qdrant
```

**SoluÃ§Ã£o**: Garantir portas 6333 e 6334 livres
```bash
# Windows
netstat -ano | findstr 6333

# Linux/Mac
lsof -i :6333
```

### Problema: Erro ao ingerir PDFs

**Causa comum**: PDFs digitalizados (imagens)

**SoluÃ§Ã£o**: 
- Use PDFs com texto extraÃ­vel
- Converta para TXT se necessÃ¡rio
- Ou adicione OCR (pytesseract) ao pipeline

**Alternativa**: Use ficheiros `.txt` para documentos de texto simples (como os exemplos fornecidos)

### Problema: Respostas sem citaÃ§Ãµes

**Verificar**:
1. Documentos foram ingeridos? `curl http://localhost:8000/stats`
2. Embeddings estÃ£o funcionando?
3. Query estÃ¡ sanitizada corretamente?

**Debug**:
```bash
# Ver logs da API
make logs-api
```

### Problema: "Rate limit exceeded"

**SoluÃ§Ã£o temporÃ¡ria**: Aumentar limite
```bash
RATE_LIMIT_PER_MINUTE=100
```

**SoluÃ§Ã£o permanente**: Implementar Redis para rate limiting distribuÃ­do

### Problema: Contexto truncado

**Sintoma**: Respostas incompletas

**SoluÃ§Ã£o**: Aumentar limite
```bash
MAX_CONTEXT_CHARS=20000
```

### Problema: Encoding UTF-8

**Erro**: `UnicodeDecodeError`

**SoluÃ§Ã£o**: Garantir ficheiros em UTF-8
```python
# Ao criar documentos
with open(file, 'r', encoding='utf-8') as f:
    ...
```

### Problema: OpenAI API timeout

**SoluÃ§Ã£o**: Aumentar timeout no provider
```python
# Em app/llm/provider.py
self.client = OpenAI(
    api_key=...,
    timeout=60.0  # segundos
)
```

## ğŸ“ Estrutura do Projeto

```
FalaProduto/
â”œâ”€â”€ api/                          # Backend FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app + endpoints
â”‚   â”‚   â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ embeddings/          # Providers de embeddings
â”‚   â”‚   â”œâ”€â”€ llm/                 # Providers LLM
â”‚   â”‚   â”œâ”€â”€ rag/                 # Pipeline RAG
â”‚   â”‚   â”œâ”€â”€ rerank/              # Re-ranking
â”‚   â”‚   â””â”€â”€ retrieval/           # Qdrant store
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â””â”€â”€ run_ragas.py         # Script avaliaÃ§Ã£o RAGAS
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ test_chat.py         # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ pytest.ini
â”‚
â”œâ”€â”€ web/                          # Frontend Next.js
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ layout.tsx           # Layout principal
â”‚   â”‚   â”œâ”€â”€ page.tsx             # PÃ¡gina chat
â”‚   â”‚   â””â”€â”€ globals.css          # Estilos globais
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Chat.tsx             # Componente chat
â”‚   â”‚   â””â”€â”€ Citations.tsx        # Componente citaÃ§Ãµes
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ tailwind.config.js
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/                     # Documentos a ingerir
â”‚   â”‚   â”œâ”€â”€ Produto_Auto_Condicoes_Gerais.txt
â”‚   â”‚   â”œâ”€â”€ Produto_Saude_Coberturas_Exclusoes.txt
â”‚   â”‚   â””â”€â”€ Produto_Habitacao_Multirriscos.txt
â”‚   â””â”€â”€ groundtruth/              # Q&A para avaliaÃ§Ã£o
â”‚       â””â”€â”€ qa.jsonl
â”‚
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ docker-compose.yml        # OrquestraÃ§Ã£o Docker
â”‚
â”œâ”€â”€ env.example                   # Template variÃ¡veis ambiente
â”œâ”€â”€ Makefile                      # Comandos Ãºteis
â””â”€â”€ README.md                     # Este ficheiro
```

## ğŸ¯ PrÃ³ximos Passos & TODOs

### Funcionalidades
- [ ] HistÃ³rico de conversaÃ§Ã£o persistente
- [ ] Suporte para mÃºltiplos idiomas
- [ ] Export de conversas (PDF/JSON)
- [ ] Feedback do utilizador (ğŸ‘/ğŸ‘)
- [ ] SugestÃµes de perguntas relacionadas

### TÃ©cnico
- [ ] Function calling para queries estruturadas
- [ ] OCR para PDFs digitalizados
- [ ] Cache de embeddings (Redis)
- [ ] MÃ©tricas com Prometheus/Grafana
- [ ] CI/CD pipeline
- [ ] Deploy em cloud (AWS/Azure/GCP)

### SeguranÃ§a
- [ ] AutenticaÃ§Ã£o (JWT)
- [ ] Rate limiting com Redis
- [ ] Audit logging
- [ ] HTTPS/TLS
- [ ] SanitizaÃ§Ã£o avanÃ§ada de inputs

### Performance
- [ ] Batch embedding generation
- [ ] Lazy loading de modelos
- [ ] Caching de resultados frequentes
- [ ] CompressÃ£o de respostas
- [ ] CDN para frontend

## ğŸ“ LicenÃ§a

Este projeto Ã© fornecido "as-is" para fins educacionais e de demonstraÃ§Ã£o.

## ğŸ¤ Contribuir

SugestÃµes e melhorias sÃ£o bem-vindas! 

## ğŸ“§ Contacto

Para questÃµes ou suporte, contacte o administrador do sistema.

---

**Desenvolvido com â¤ï¸ usando FastAPI, Next.js, Qdrant e OpenAI**


